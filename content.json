{   
    "pagetitle":"Rahul_Das_Resume",
    "personal": {
        "name" : "Rahul Das",
        "dob" : "13-03-1988 ",
        "address":"Kolkata, India, 711109",
        "github":"https://github.com/RahulDas-dev",
        "github-short":"github.com/RahulDas-dev",
        "twitter":"https://twitter.com/Rahul13031988",
        "linkedin":"https://in.linkedin.com/in/contact-rahul",
        "linkedin-short": "likedin.com/contact-rahul",
        "mobile": "+91 8097397804",
        "mail":"r.das699@gmail.com",
        "experience":"10+ years of experience",
        "gitrepo":"https://github.com/RahulDas-dev/rahul_resume"
    },
    "title": "Hi, I am Rahul",
    "sub_title" : "Data Science & Machine Learning Professionals",
    "content": "I have 10+ years of industry experience including 5+ years in Data Science, specially in the Retail domain. During my tenure at TCS, I was able to gain expertise in Machine Learning, Deep Learning, Image processing, Linear Algebra, and Statistics. Besides Python, I've used Javascript and Typescript to create dashboards and visualizations. Currently I am looking for opportunities to apply my expertise and learn further.",
    "career":{
        "title": "Relevant Experience",
        "items":[
          {
            "desig":"Assistant Consultant",
            "role": "Data Scientist & ML Engineer",
            "date":"Current Date",
            "projects":[
              {
                "title":"Pricing Optimization",
                "client":"Barnes & Noble, Walgreens",
                "functionalities":"Manually setting and maintaining prices for high-class merchandise in retail stores is a significant burden. Adjusting items prices for competitiveness and seasonality magnifies the problem. Retailers want a all-in-one solution for daily price management, category reset, trade correction and seasonal pricing.",
                "roles":["Modeling the demand and price relationship taking into account self Elasticity, Cross and Competitor Elasticity.",
                        "Model vectorization for parallel processing across GPU.",
                      "The demand and price relationship is exceedingly complex and difficult to optimise. However, I used the Gradient Descent Algorithm to optimize the demand. ",
                      "Computation of Elasticity and Cross Elasticity using Linear Regression + regularization.",
                      "Projecting future demand for any arbitary price change using demand Gradient."],
                "tools":["python3","numpy", "pyspark", "pandas", "matplot-lib","sql", "Tensorflow"]      
              },{
                "title":"Item / Buddy Matching ",
                "client":"Walgreens",
                "functionalities":"Manually organizing big class of merchandise for Retailers is a headache. The Retailers want to identify all comparable item/buddy under same clustering using image or textual information.",
                "roles":["Clustering using textual information --",
                        "Given product titles, brand, manufracturer info and other quantifying their diploma of similarity using, Feature selection followed by clustering",
                        "Feature Selection - I use PCA and SVD to undertake Feature Engineering that demonstrates the highest level of reliability.",
                        "Feature Selection - Adding and removing one feature at a time while monitoring the decision tree's accuracy metric. Then selecting features with highest accuracy",
                        "Finally clustering Feature vectors is done using Hierarchical clustering algo.",
                        "Similarity measurement using image -- ",
                        "We trained Convolutional Auto-encoder using similar image pairs as network traing data.",
                        "The output of the Encoder Layer has been extracted from a trained Model. Finally Kmeans Clustering has been done."
                      ],
                "tools":["python3", "Tendorflow","keras","matplot-lib","numpy","opencv"]
              }
            ]
          },
          {
            "desig":"IT Analyst",
            "role": "Data Scientist & ML Engineer",
            "date":"Jun 2021",
            "projects":[
              {
                "title":"Dashboard Building / Visualization Tool",
                "functionalities":"Data-science projects require interactive ways to share visuals of various graphs, charts, map and other visual information. Web-based dashboards are an effective solution. However the task became challenging sometimes,  when creating visualization for N-Dimensional data ,Or Visualization for intermediate layers of Deep Neural Network.",
                "tools":["D3.js", "Javascript","Python3","flask","matplot-lib"]
              }
            ]
          }
        ]
    },
    "career2":{
      "items":[
        {
          "projects":[
            {
              "title":"Product Identification / Object Detection",
              "client":"Walgreens",
              "functionalities":"Detect empty shelves in retail stores and refill empty shelves with the exact items specified in the planogram is a retailer's daily business. However, the task complexity increases exponentially with the number of merchandise items. Retailer wants a mobile app-based solution to support store owners. App will Organize missing shelves and replenish new value according to planogram compliance. As a deep learning engineer, my job was to detect empty positions of the shelvs from images captured by mobile apps, And Recognize the Product of filledup shelves.",
              "roles":["Image dataset collection by web scraping with Python script.",
                      "Image dataset preprocessing, meta tag removal, resizing, image annotation.",
                    "The main task of object recognition was taken over by YOLOV3. However, I did experimentation FRCNN.",
                    "Training of state-of-the-art Yolov3 models [transfer learning].",
                    "Monitoring the training process with Tensorboard and hyperparameter tuning.",
                    "Deployed a trained model using Tensorflow-serving."],
              "tools":["python3","Tendorflow","keras", "Tensorboard","Tensorflow-serving","scikit-learn","matplot-lib","opencv" ] 
            },
            {
              "title":"Associative Rule Mining",
              "client":"Walgreens",
              "functionalities":"Retailers want to find associations among large sets of particulars which are constantly brought together. In a sense this seems finding similarity between the particulars, but its not. Ex- Bread and Butter are frequently brought together. This association helps retailer to organize the Planogram accordingly, so the associated particulars can placed near by shelves. As a data scientist we had the job to find out that association.",
              "roles":["Data preprocessing - collecting daily invoice data from OLAP and mapping the items that are frequently brought together using Numpy Matric / Pivot Table",
                      "I use Apriori Algorithm which is a Unsupervised Learning technique. ",
                      "That main difficulty with Apriori algorithm is it has time complexity of O(2^n). So we itroduced a technique to store the conditional probability generated by algorithem from original data set. We reuse the conditionally probabilities in case of incremental data. This results lower time consumption in case of incremental data."
                    ],
              "tools":["python3","scikit-learn","matplot-lib","numpy" ] 
            }
          ]
        },
        {
          "desig":"System Engineer",
          "role": "Back end Developer",
          "date":"Aug 2017",
          "projects":[
            {
              "title":"Core Banking Solution [ CBS ]",
              "client":"State Bank of India",
              "functionalities":"Execution of core banking system across all branches and speed up all finantial transactions, automation of EOD interests calculation and ofline reporting.",
              "roles":["Enhancements for interest calculation for loan products.",
              "Change request implementation for parameter change, customer level limit tree creation, NPA, Financial transaction.", 
              "Change request implementation for currency chest, loan account opening process.",
              "Offline and ad-hoc report generation."
              ],
              "tools":["Sql", "COBOL","Unix"]
            }
          ]
        },{
          "date":"Jul 2012",
          "projects":[
          ]
        }
      ]
    },
    "onlineCouse":{
      "title":"Online Course",
      "name":"Deep Learning Specilization",
      "source":"Coursera",
      "url":"https://www.coursera.org/account/accomplishments/specialization/G9BU6M6NP8KQ",
      "logo": "https://www.vectorlogo.zone/logos/coursera/coursera-ar21.svg",
      "subtopics":[
        {
          "title":"Neural Networks and Deep Learning",
          "suburl":"https://www.coursera.org/account/accomplishments/verify/KJW4VJJ8GKFC"
        },
        {
          "title":"Structuring ML Projects",
          "suburl":"https://www.coursera.org/account/accomplishments/verify/HSAYYFRUXLM9"
        },
        {
          "title":"Improving Deep Neural Networks",
          "suburl":"https://www.coursera.org/account/accomplishments/verify/7LJTMTL3SM2K"
        },{
          "title":"Convolutional Neural Networks",
          "suburl":"https://www.coursera.org/account/accomplishments/verify/4DXE2DR3B6ZN"
        },
        {
          "title":"Sequence Models",
          "suburl":"https://www.coursera.org/account/accomplishments/verify/PJGX3DW4N5G9"
        }
      ]
    },
    "certification":{
      "title":"Certification",
      "sub_title":"Learning never exhausts the mind.",
      "items":[
        {
          "title":"3D Reconstruction from Image ",
          "details":"This specialization presents the first comprehensive treatment of the foundations of computer vision. This course focuses on the recovery of the 3D structure of a scene from its 2D images.",
          "source":"Coursera",
          "logo":"https://www.vectorlogo.zone/logos/coursera/coursera-ar21.svg",
          "suburl":"https://www.coursera.org/account/accomplishments/verify/N57QGYMJKW3K"
        },{
          "title":"Modern Javascript Bootcamp",
          "source":"udemy",
          "details": "The comprehensive and in-depth JavaScript course ,in great detail. It's a huge course because it's packed with important knowledge and helpful content. From the core basics, over advanced concepts and JavaScript specialties",
          "logo": "https://www.vectorlogo.zone/logos/udemy/udemy-ar21.svg",
          "suburl":"https://www.udemy.com/certificate/UC-fd20264f-51dd-4c8f-b9c7-8e5ee8997c6d/"
        }],
        "mitems":{
          "title":"Google Cloud",
          "source":"Coursera",
          "logo":"https://www.vectorlogo.zone/logos/coursera/coursera-ar21.svg",
          "url":"https://www.coursera.org/account/accomplishments/certificate/PQ24BMT3U4H5",
          "items":[
            {
              "title":"Google Cloud Fundamentals",
              "suburl": "https://www.coursera.org/account/accomplishments/certificate/F6PVH5BJ5WRW"
            },
            {
              "title":"Google Cloud Infrastructure",
              "suburl": "https://www.coursera.org/account/accomplishments/certificate/PQ24BMT3U4H5"
            },
            {
              "title":"Google Core Services",
              "suburl": "https://www.coursera.org/account/accomplishments/certificate/69JF5URD72BV"
            },{
              "title":"Scaling and Automation",
              "suburl": "https://www.coursera.org/account/accomplishments/certificate/UWKECY44XMQU"
            },{
              "title":"Google Kubernetes Engine",
              "suburl": "https://www.coursera.org/account/accomplishments/certificate/SWEV92PPQ2RU"
            }
          ]
        }
    },
    "education":{
        "title": "Academics",
        "sub_title" : "Data Science, ML Engineer",
        "items":[
            {
                "degree": "M.tech",
                "subject": "Communication Engineering",
                "University": "NIT Durgapur",
                "period": "2010-2012",
                "marks": "CGPA 9.1",
                "url": "https://nitdgp.ac.in/"
            },
            {
                "degree": "B.tech",
                "subject": "Electronics & Comm Engineering",
                "University": "West Bengal University of technology",
                "period": "2005-2009",
                "marks": "CGPA 8.5",
                "url" : "https://makautwb.ac.in/"
            }
        ]
    },
    "skills":{
      "items":[
        {
          "name": "Python",
          "duration": "6 Years",
          "pkges":["core-library","type-hinting","unit-testing","asyncio"]
        },
        {
          "name": "Data Science ",
          "pkges":["numpy", "scikit-learn","pandas","pyspark", "scipy", "matplotlib", "seaborn", "opencv"],
          "duration": "5 Years"
        },
        {
          "name": "ML/DL Framework",
          "pkges":["tensorflow","Keras", "pytorch"],
          "duration": "4 Years"
        },
        {
          "name": "SQL Database",
          "pkges":["postgres","Azure Databrics", "Python/sqlite3","pyspark"],
          "duration": "4 Years"
        },{
          "name": "DS Fundamentals",
          "pkges":["Statistics", "Linear Algebra"],
          "duration": "4 Years"
        }
      ]
    },
    "otherskills":{
      "title": "My Leaning Stack",
      "desc":"Given the present state of technology, I am developing certain skills, but I am not officially using them in my current company.",
      "items":["Rust","JavaScpript","TypeScript","Webpack","React"]
    },
    "achivements": {
      "title": "Achievement",
      "items":["Oct 2016 - Technical Excellence Award for successful automation of Agricultural Subvention Reporting"]
    },
    "footer":{
      "repolink" : "https://github.com/RahulDas-dev/rahul_resume",
      "line1": "Designed & Built by Rahul Das  ",
      "line2": "A framework-free, responsive design bundled with vite."
    }
}



